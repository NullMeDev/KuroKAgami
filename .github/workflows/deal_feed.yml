name: Scrape & Post Deals

on:
  schedule:
    - cron: "0 */3 * * *"        # every 3 hours
  workflow_dispatch:
  push:
    paths-ignore:
      - 'data/deals.sqlite'

concurrency:
  group: deal-feed
  cancel-in-progress: true

jobs:
  run:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4
        with:
          token: ${{ secrets.GITHUB_TOKEN }}

      - uses: actions/cache@v4
        with:
          path: ~/.cache/pip
          key: ${{ runner.os }}-pip-${{ hashFiles('requirements.txt') }}

      - uses: actions/setup-python@v5
        with:
          python-version: "3.12"

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements.txt

      - name: Run selector tests
        run: pytest -q tests

      - name: Scrape & post deals
        env:
          DISCORD_WEBHOOKS: ${{ secrets.DISCORD_WEBHOOKS }}
          DISCORD_WEBHOOK: ${{ secrets.DISCORD_WEBHOOK }}
        run: python main.py --force all > metrics.json

      - name: Skip cache comit 
      run: echo "Cache-comit step disabled to avoid errors"

      - name: Alert if no fresh deals
        if: success()
        uses: actions/github-script@v7
        with:
          script: |
            const metrics = require('./metrics.json');
            if ((metrics.fresh_deals||[]).length === 0) {
              await github.rest.issues.create({
                owner: context.repo.owner,
                repo: context.repo.repo,
                title: "Deal Bot: No fresh deals",
                body: "No fresh deals detected in the last run.",
                labels: ["bot-alert"]
              });
            }
